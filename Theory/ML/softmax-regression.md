Status: **Editing**

Tags:[[Machine Learning]]

# softmax-regression

$$\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o}) \quad \textrm{where}\quad \hat{y}_i = \frac{\exp(o_i)}{\sum_j \exp(o_j)}.$$
where o is the target from linear regression

no need to compute softmax preserves ordering
$$\operatorname*{argmax}_j \hat y_j = \operatorname*{argmax}_j o_j.$$


# References