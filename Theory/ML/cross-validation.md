Status: **Editing**

Tags:[[Machine Learning]]

# cross-validation

Training data is scarce so K-fold cross-validation. The original data is split into K non-overlapping subsets. 
K_i is chosen as validation and rest is training, do this K times, record training/validation errors and average them.



# References